#!/usr/bin/env python3

import libspn as spn
from enum import Enum


class Dataset(Enum):
    IMAGE = 0
    MNIST = 1


class Model(Enum):
    DISCRETE_DENSE = 0


class Learner(Enum):
    EM = 0


class WeightInitType(Enum):
    ONE = 1
    RANDOM = 2


class SpnModel(spn.App):

    def __init__(self):
        super().__init__("Model")

    def _define_build_args(self, parser):
        parser.add_argument('model', type=str,
                            choices=[i.name.lower() for i in Model],
                            help="model to build")

        model_params = parser.add_argument_group(title="model parameters")
        model_params.add_argument('--weight-init', type=str, default='random',
                                  help='weight initialization: ' +
                                  ', '.join([a.name.lower() for a in WeightInitType]))
        model_params.add_argument('--dense-decomps', type=int, default=1,
                                  help='dense generator: number of decompositions')
        model_params.add_argument('--dense-subsets', type=int, default=2,
                                  help='dense generator: number of subsets')
        model_params.add_argument('--dense-mixtures', type=int, default=4,
                                  help='dense generator: number of mixtures')
        model_params.add_argument('--dense-input-dist', type=str, default='raw',
                                  help='dense generator: input distributions: ' +
                                  ', '.join([a.name.lower()
                                             for a in spn.DenseSPNGenerator.InputDist]))
        model_params.add_argument('--dense-input-mixtures', type=int, default=3,
                                  help='dense generator: number of input mixtures')

    def _define_load_args(self, parser):
        parser.add_argument('path', type=str,
                            help="path to the model")

    def _define_train_args(self, parser):
        parser.add_argument('learner', type=str,
                            choices=[i.name.lower() for i in Learner],
                            help="learner to use")
        parser.add_argument('dataset', type=str,
                            choices=[i.name.lower() for i in Dataset],
                            help="training dataset to use")
        parser.add_argument('path', type=str,
                            help="path to the training data; "
                            "a folder, a glob, or a coma-separated list of files")

        data_params = parser.add_argument_group(title="data parameters")
        data_params.add_argument('--num-epochs', type=int, default='100',
                                 help="number of training epochs")
        data_params.add_argument('--batch-size', type=int, default='100',
                                 help="size of a batch used for training")
        data_params.add_argument('--allow_smaller_batch', action='store_true',
                                 help="allow smaller final batch")
        data_params.add_argument('--num-threads', type=int, default='1',
                                 help="number of threads enqueuing the data queue.")
        data_params.add_argument('--shuffle', action='store_true',
                                 help="shuffle the data every epoch")
        data_params.add_argument('--seed', type=int, default=None,
                                 help="seed used for shuffling")

        image_params = parser.add_argument_group(title="image data parameters")
        image_params.add_argument('--image-format', type=str, default='float',
                                  choices=[i.name.lower()
                                           for i in spn.ImageFormat],
                                  help="image format")
        image_params.add_argument('--ratio', type=int, default=1,
                                  help="downsample images by the given ratio")
        image_params.add_argument('--crop', type=int, default=0,
                                  help="crop image border pixels")

        mnist_params = parser.add_argument_group(title="MNIST data parameters")
        mnist_params.add_argument('--mnist-subset', type=str, default='all',
                                  choices=[i.name.lower()
                                           for i in spn.MnistDataset.Subset],
                                  help="subset to use")
        mnist_params.add_argument('--mnist-classes', type=str, default=None,
                                  help="coma-separated list of digits; if specified, "
                                  "only the listed classes will be provided")

        learn_params = parser.add_argument_group(title="learning parameters")
        learn_params.add_argument('--value-inference', type=str, default='marginal',
                                  help='Type of inference during EM upwards pass: ' +
                                  ', '.join([a.name.lower() for a in spn.InferenceType]))
        learn_params.add_argument('--init-accum', type=int, default=20,
                                  help='Initial accumulator value')
        learn_params.add_argument('--smoothing-val', type=float, default=0.0,
                                  help='Additive smoothing value')
        learn_params.add_argument('--smoothing-decay', type=float, default=0.2,
                                  help='Additive smoothing decay')
        learn_params.add_argument('--smoothing-min', type=float, default=0.0,
                                  help='Additive smoothing min value')
        learn_params.add_argument('--stop-condition', type=float, default=0.05,
                                  help='Min likelihood change between epochs')

    def _define_test_args(self, parser):
        parser.add_argument('dataset', type=str,
                            choices=[i.name.lower() for i in Dataset],
                            help="test dataset to use")
        parser.add_argument('path', type=str,
                            help="path to the test data; "
                            "a folder, a glob, or a coma-separated list of files")

        data_params = parser.add_argument_group(title="data parameters")
        data_params.add_argument('--batch-size', type=int, default='100',
                                 help="size of a batch used for training")
        data_params.add_argument('--num-threads', type=int, default='1',
                                 help="number of threads enqueuing the data queue.")

        image_params = parser.add_argument_group(title="image data parameters")
        image_params.add_argument('--image-format', type=str, default='float',
                                  choices=[i.name.lower()
                                           for i in spn.ImageFormat],
                                  help="image format")
        image_params.add_argument('--ratio', type=int, default=1,
                                  help="downsample images by the given ratio")
        image_params.add_argument('--crop', type=int, default=0,
                                  help="crop image border pixels")

        mnist_params = parser.add_argument_group(title="MNIST data parameters")
        mnist_params.add_argument('--mnist-subset', type=str, default='all',
                                  choices=[i.name.lower()
                                           for i in spn.MnistDataset.Subset],
                                  help="subset to use")
        mnist_params.add_argument('--mnist-classes', type=str, default=None,
                                  help="coma-separated list of digits; if specified, "
                                  "only the listed classes will be provided")

    def _define_mpe_args(self, parser):
        pass

    def _define_save_args(self, parser):
        pass

    def define_args(self, parser, commands):
        self._define_load_args(
            commands.add_parser('load', app=self,
                                help='load a model'))
        self._define_build_args(
            commands.add_parser('build', app=self,
                                help='build model structure'))
        self._define_train_args(
            commands.add_parser('train', app=self,
                                help='train a model'))
        self._define_test_args(
            commands.add_parser('test', app=self,
                                help='get p(labels|data)'))
        self._define_mpe_args(
            commands.add_parser('mpe', app=self,
                                help='get mpe state of data variables'))
        self._define_save_args(
            commands.add_parser('save', app=self,
                                help='save a model'))

    def process_args(self, parser, args):
        if (args.build is None) == (args.load is None):
            parser.error("build xor load command must be used")

        if args.build and not args.train:  # build implies train
            parser.error("missing train command")

        ##########################
        # Build command
        ##########################
        # Positional
        args.build.model = Model[args.build.model.upper()]
        # Model
        args.build.dense_input_dist = spn.DenseSPNGenerator.InputDist[
            args.build.dense_input_dist.upper()]
        args.build.weight_init = WeightInitType[args.build.weight_init.upper()]

        ##########################
        # Train command
        ##########################
        # Positional
        args.train.dataset = Dataset[args.train.dataset.upper()]
        # Data
        args.train.image_format = spn.ImageFormat[args.train.image_format.upper()]
        if args.train.ratio < 1:
            parser.error("RATIO must be >=1")
        if args.train.crop < 0:
            parser.error("CROP cannot be negative")
        args.train.mnist_subset = spn.MnistDataset.Subset[args.train.mnist_subset.upper()]
        if args.train.mnist_classes is not None:
            try:
                args.train.mnist_classes = set([int(i) for i in
                                                args.train.mnist_classes.split(',')])
            except ValueError:
                parser.error("Incorrect mnist_classes '%s'" % args.train.mnist_classes)
        # Learning
        args.train.value_inference = spn.InferenceType[args.train.value_inference.upper()]

        ##########################
        # Test command
        ##########################
        # Positional
        args.test.dataset = Dataset[args.test.dataset.upper()]
        # Data
        args.test.image_format = spn.ImageFormat[args.test.image_format.upper()]
        if args.test.ratio < 1:
            parser.error("RATIO must be >=1")
        if args.test.crop < 0:
            parser.error("CROP cannot be negative")
        args.test.mnist_subset = spn.MnistDataset.Subset[args.test.mnist_subset.upper()]
        if args.test.mnist_classes is not None:
            try:
                args.test.mnist_classes = set([int(i) for i in
                                               args.test.mnist_classes.split(',')])
            except ValueError:
                parser.error("Incorrect mnist_classes '%s'" % args.test.mnist_classes)

    def _prepare_data(self, args):
        if args.train:
            if args.train.dataset == Dataset.MNIST:
                self.train_set = spn.MnistDataset(
                    data_dir=args.train.path,
                    subset=args.train.mnist_subset,
                    format=args.train.image_format,
                    num_epochs=args.train.num_epochs,
                    batch_size=args.train.batch_size,
                    shuffle=args.train.shuffle,
                    ratio=args.train.ratio,
                    crop=args.train.crop,
                    num_threads=args.train.num_threads,
                    allow_smaller_final_batch=args.train.allow_smaller_batch,
                    classes=args.train.mnist_classes,
                    seed=args.train.seed)
                self.train_samples, self.train_labels = self.train_set.get_data()
            elif args.train.dataset == Dataset.IMAGE:
                self.train_set = spn.ImageDataset(
                    image_files=args.train.path,
                    format=args.train.image_format,
                    num_epochs=args.train.num_epochs,
                    batch_size=args.train.batch_size,
                    shuffle=args.train.shuffle,
                    ratio=args.train.ratio,
                    crop=args.train.crop,
                    num_threads=args.train.num_threads,
                    allow_smaller_final_batch=args.train.allow_smaller_batch,
                    seed=args.train.seed)
                self.train_samples, self.train_labels = self.train_set.get_data()
            # For a dataset without labels, just set labels to None
        if args.test:
            if args.test.dataset == Dataset.MNIST:
                self.test_set = spn.MnistDataset(data_dir=args.test.path,
                                                 subset=args.test.mnist_subset,
                                                 format=args.test.image_format,
                                                 num_epochs=1,
                                                 batch_size=args.test.batch_size,
                                                 shuffle=False,
                                                 ratio=args.test.ratio,
                                                 crop=args.test.crop,
                                                 num_threads=args.test.num_threads,
                                                 allow_smaller_final_batch=True,
                                                 classes=args.test.mnist_classes)
                self.test_samples, self.test_labels = self.test_set.get_data()
            elif args.test.dataset == Dataset.IMAGE:
                self.test_set = spn.ImageDataset(image_files=args.test.path,
                                                 format=args.test.image_format,
                                                 num_epochs=1,
                                                 batch_size=args.test.batch_size,
                                                 shuffle=False,
                                                 ratio=args.test.ratio,
                                                 crop=args.test.crop,
                                                 num_threads=args.test.num_threads,
                                                 allow_smaller_final_batch=True)
                self.test_samples, self.test_labels = self.test_set.get_data()
            # For a dataset without labels, just set labels to None

    def _load_model(self, args):
        pass

    def _build_model(self, args):
        # Decode weight_init_value
        if args.build.weight_init == WeightInitType.ONE:
            weight_init_value = 1
        elif args.build.weight_init == WeightInitType.RANDOM:
            weight_init_value = spn.ValueType.RANDOM_UNIFORM(0, 1)
        # Build model
        if args.build.model == Model.DISCRETE_DENSE:
            self.model = spn.DiscreteDenseModel(
                num_decomps=args.build.dense_decomps,
                num_subsets=args.build.dense_subsets,
                num_mixtures=args.build.dense_mixtures,
                input_dist=args.build.dense_input_dist,
                num_input_mixtures=args.build.dense_input_mixtures,
                weight_init_value=weight_init_value)
            self.model.build()

    def _train_model(self, args):
        pass
        # TODO: train, test etc., feed appropriate data through feed_dict
        # model.learn(value_inference_type=args.learn.value_inference,
        #             init_accum_value=args.learn.init_accum,
        #             additive_smoothing_value=args.learn.smoothing_val,
        #             additive_smoothing_decay=args.learn.smoothing_decay,
        #             additive_smoothing_min=args.learn.smoothing_min,
        #             stop_condition=args.learn.stop_condition)

        # Save TF graph
        # self.print2("Saving TensorFlow graph")
        # writer = tf.summary.FileWriter("./logs", self._root.tf_graph)
        # writer.flush()

    def _test_model(self, args):
        pass

    def _save_model(self, args):
        pass

    def run(self, args):
        self._prepare_data(args)
        if args.build:
            self._build_model(args)
        elif args.load:
            self._load_model(args)
        if args.train:
            self._train_model(args)
        if args.test:
            self._test_model(args)
        if args.save:
            self._save_model(args)


if __name__ == '__main__':
    app = SpnModel()
    app.main()
