#!/usr/bin/env python3

import libspn as spn
from collections import namedtuple
from enum import Enum


class Dataset(Enum):
    IMAGES = 0
    MNIST = 1


class Model(Enum):
    DENSE = 0


class WeightInitType(Enum):
    ONE = 1
    RANDOM = 2


class SpnModel(spn.App):

    TrainParams = namedtuple('TrainParams', ['model', 'dataset'])

    def __init__(self):
        super().__init__("Model")

    def define_args(self, parser, commands):
        ##########################
        # Train command
        ##########################
        train_parser = commands.add_parser('train', app=self,
                                           help='train a model')
        train_parser.add_argument('model', type=str,
                                  choices=[i.name.lower() for i in Model],
                                  help="model to train")
        train_parser.add_argument('dataset', type=str,
                                  choices=[i.name.lower() for i in Dataset],
                                  help="training dataset to use")
        train_parser.add_argument('path', type=str,
                                  help="path to the training data; "
                                  "a folder, a glob, or a coma-separated list of files")

        data_params = train_parser.add_argument_group(title="data parameters")
        data_params.add_argument('--num-epochs', type=int, default='100',
                                 help="number of training epochs")
        data_params.add_argument('--batch-size', type=int, default='100',
                                 help="size of a batch used for training")
        data_params.add_argument('--num-threads', type=int, default='1',
                                 help="number of threads enqueuing the data queue.")
        data_params.add_argument('--shuffle', action='store_true',
                                 help="shuffle the data every epoch")
        data_params.add_argument('--seed', type=int, default=None,
                                 help="seed used for shuffling")

        image_params = train_parser.add_argument_group(title="image data parameters")
        image_params.add_argument('--image-format', type=str, default='float',
                                  choices=[i.name.lower()
                                           for i in spn.ImageFormat],
                                  help="image format")
        image_params.add_argument('--ratio', type=int, default=1,
                                  help="downsample images by the given ratio")
        image_params.add_argument('--crop', type=int, default=0,
                                  help="crop image border pixels")

        mnist_params = train_parser.add_argument_group(title="MNIST data parameters")
        mnist_params.add_argument('--mnist-subset', type=str, default='all',
                                  choices=[i.name.lower()
                                           for i in spn.MnistDataset.Subset],
                                  help="subset to use")
        mnist_params.add_argument('--mnist-classes', type=str, default=None,
                                  help="coma-separated list of digits; if specified, "
                                  "only the listed classes will be provided")

        model_params = train_parser.add_argument_group(title="model parameters")
        model_params.add_argument('--dense-decomps', type=int, default=1,
                                  help='Dense generator: Number of decompositions')
        model_params.add_argument('--dense-subsets', type=int, default=2,
                                  help='Dense generator: Number of subsets')
        model_params.add_argument('--dense-mixtures', type=int, default=4,
                                  help='Dense generator: Number of mixtures')
        model_params.add_argument('--dense-input-dist', type=str, default='raw',
                                  help='Dense generator: Input distributions: ' +
                                  ', '.join([a.name.lower()
                                             for a in spn.DenseSPNGenerator.InputDist]))
        model_params.add_argument('--dense-input-mixtures', type=int, default=3,
                                  help='Dense generator: Number of input mixtures')

        learn_params = train_parser.add_argument_group(title="learning parameters")
        learn_params.add_argument('--weight-init', type=str, default='random',
                                  help='Weight init value: ' +
                                  ', '.join([a.name.lower() for a in WeightInitType]))
        learn_params.add_argument('--value-inference', type=str, default='marginal',
                                  help='Type of inference during EM upwards pass: ' +
                                  ', '.join([a.name.lower() for a in spn.InferenceType]))
        learn_params.add_argument('--init-accum', type=int, default=20,
                                  help='Initial accumulator value')
        learn_params.add_argument('--smoothing-val', type=float, default=0.0,
                                  help='Additive smoothing value')
        learn_params.add_argument('--smoothing-decay', type=float, default=0.2,
                                  help='Additive smoothing decay')
        learn_params.add_argument('--smoothing-min', type=float, default=0.0,
                                  help='Additive smoothing min value')
        learn_params.add_argument('--stop-condition', type=float, default=0.05,
                                  help='Min likelihood change between epochs')

        ##########################
        # Load command
        ##########################
        load_parser = commands.add_parser('load', app=self,
                                          help='load a model')
        load_parser.add_argument('path', type=str,
                                 help="path to the model")

        ##########################
        # MPE command
        ##########################
        mpe_parser = commands.add_parser('mpe', app=self,
                                         help='get mpe state of data variables')

    def process_args(self, parser, args):
        if args.train is None and args.load is None:
            parser.error("either train or load command must be used")

        ##########################
        # Train command
        ##########################
        # Positional
        args.train.model = Model[args.train.model.upper()]
        args.train.dataset = Dataset[args.train.dataset.upper()]
        # Data
        args.train.image_format = spn.ImageFormat[args.train.image_format.upper()]
        if args.train.ratio < 1:
            parser.error("RATIO must be >=1")
        if args.train.crop < 0:
            parser.error("CROP cannot be negative")
        args.train.mnist_subset = spn.MnistDataset.Subset[args.train.mnist_subset.upper()]
        if args.train.mnist_classes is not None:
            try:
                args.train.mnist_classes = set([int(i) for i in
                                                args.train.mnist_classes.split(',')])
            except ValueError:
                parser.error("Incorrect mnist_classes '%s'" % args.train.mnist_classes)
        # Model
        args.train.dense_input_dist = spn.DenseSPNGenerator.InputDist[
            args.train.dense_input_dist.upper()]
        args.train.weight_init = WeightInitType[args.train.weight_init.upper()]
        args.train.value_inference = spn.InferenceType[args.train.value_inference.upper()]

    def run(self, args):
        ##########################
        # Train command
        ##########################
        if args.train is not None:
            # Create dataset
            if args.train.dataset == Dataset.MNIST:
                dataset = spn.MnistDataset(data_dir=args.train.path,
                                           subset=args.train.mnist_subset,
                                           format=args.train.image_format,
                                           num_epochs=args.train.num_epochs,
                                           batch_size=args.train.batch_size,
                                           shuffle=args.train.shuffle,
                                           ratio=args.train.ratio,
                                           crop=args.train.crop,
                                           num_threads=args.train.num_threads,
                                           allow_smaller_final_batch=True,
                                           classes=args.train.mnist_classes,
                                           seed=args.train.seed)
            elif args.train.dataset == Dataset.IMAGE:
                dataset = spn.ImageDataset(image_files=args.train.path,
                                           format=args.train.image_format,
                                           num_epochs=args.train.num_epochs,
                                           batch_size=args.train.batch_size,
                                           shuffle=args.train.shuffle,
                                           ratio=args.train.ratio,
                                           crop=args.train.crop,
                                           num_threads=args.train.num_threads,
                                           allow_smaller_final_batch=True,
                                           seed=args.train.seed)
            # Decode weight_init_value
            if args.train.weight_init == WeightInitType.ONE:
                weight_init_value = 1
            elif args.train.weight_init == WeightInitType.RANDOM:
                weight_init_value = spn.ValueType.RANDOM_UNIFORM(0, 1)
            # Train model
            if args.train.model == Model.DENSE:
                model = spn.DenseModel()
                model.build_spn(dataset,
                                num_decomps=args.train.dense_decomps,
                                num_subsets=args.train.dense_subsets,
                                num_mixtures=args.train.dense_mixtures,
                                input_dist=args.train.dense_input_dist,
                                num_input_mixtures=args.train.dense_input_mixtures,
                                weight_init_value=weight_init_value)
                # model.save_graph()
                model.train(value_inference_type=args.train.value_inference,
                            init_accum_value=args.train.init_accum,
                            additive_smoothing_value=args.train.smoothing_val,
                            additive_smoothing_decay=args.train.smoothing_decay,
                            additive_smoothing_min=args.train.smoothing_min,
                            stop_condition=args.train.stop_condition)

        ##########################
        # MPE command
        ##########################
        if args.mpe is not None:
            pass


if __name__ == '__main__':
    app = SpnModel()
    app.main()
