# -*- coding: utf-8 -*-
"""Copy of LibSPN DGC-SPN digit classification tutorial.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Ctl3kgZ9SLfQZzf4ub-9Xs6ZMPIkfZoq

# Training a Deep Generalized Convolutional Sum-Product Network (DGC-SPN) for image completion.
Let's go through an example of building complex SPNs with [`libspn-keras`](https://github.com/pronobis/libspn-keras). The layer-based API of the library makes it straightforward to build advanced SPN architectures.

First let's set up the dependencies:
"""

import tensorflow as tf

gpus = tf.config.experimental.list_physical_devices('GPU')
if gpus:
    try:
        # Currently, memory growth needs to be the same across GPUs
        for gpu in gpus:
            tf.config.experimental.set_memory_growth(gpu, True)
        logical_gpus = tf.config.experimental.list_logical_devices('GPU')
        print(len(gpus), "Physical GPUs,", len(logical_gpus), "Logical GPUs")
    except RuntimeError as e:
        # Memory growth must be set before GPUs have been initialized
        print(e)

import numpy as np

def load_olivetti(test_size=50):
    x = np.loadtxt("../mnist_olivetti/olivetti.raw").transpose().reshape(
        400, 64, 64).transpose((0, 2, 1)).astype(np.float32)
    train_x = x[:-test_size]
    test_x = x[-test_size:]
    return train_x, test_x

train_x, test_x = load_olivetti()

import libspn_keras as spn
from libspn_keras import layers, initializers
from tensorflow import keras


def build_sum_product_network(backprop_mode):
    sum_kwargs = dict(
        accumulator_initializer=initializers.EpsilonInverseFanIn(axis=2, epsilon=1e-4),
        logspace_accumulators=False, backprop_mode=backprop_mode
    )

    location_initializer = initializers.PoonDomingosMeanOfQuantileSplit(
        data=train_x.squeeze(), normalization_epsilon=1e-8)

    sum_product_network = keras.Sequential([
        layers.NormalLeaf(
            input_shape=(64, 64, 1),
            num_components=4,
            location_trainable=False,
            scale_trainable=False,
            dimension_permutation=spn.DimensionPermutation.BATCH_FIRST,
            location_initializer=location_initializer
        ),
        # Non-overlapping products
        layers.Conv2DProduct(
            depthwise=True,
            strides=[1, 1],
            dilations=[1, 1],
            kernel_size=[2, 2],
            padding='full'
        ),
        layers.Local2DSum(num_sums=2, **sum_kwargs),
        # Non-overlapping products
        layers.Conv2DProduct(
            depthwise=False,
            strides=[1, 1],
            dilations=[2, 2],
            kernel_size=[2, 2],
            padding='full'
        ),
        layers.Local2DSum(num_sums=2, **sum_kwargs),
        # Overlapping products, starting at dilations [1, 1]
        layers.Conv2DProduct(
            depthwise=False,
            strides=[1, 1],
            dilations=[4, 4],
            kernel_size=[2, 2],
            padding='full'
        ),
        layers.Local2DSum(num_sums=2, **sum_kwargs),
        # Overlapping products, with dilations [2, 2] and full padding
        layers.Conv2DProduct(
            depthwise=False,
            strides=[1, 1],
            dilations=[8, 8],
            kernel_size=[2, 2],
            padding='full'
        ),
        layers.Local2DSum(num_sums=2, **sum_kwargs),
        # Overlapping products, with dilations [2, 2] and full padding
        layers.Conv2DProduct(
            depthwise=False,
            strides=[1, 1],
            dilations=[16, 16],
            kernel_size=[2, 2],
            padding='full'
        ),
        layers.Local2DSum(num_sums=2, **sum_kwargs),
        layers.Conv2DProduct(
            depthwise=False,
            strides=[1, 1],
            dilations=[32, 32],
            kernel_size=[2, 2],
            padding='full'
        ),
        layers.Local2DSum(num_sums=2, **sum_kwargs),
        # Overlapping products, with dilations [2, 2] and 'final' padding to combine
        # all scopes
        layers.Conv2DProduct(
            depthwise=False,
            strides=[1, 1],
            dilations=[64, 64],
            kernel_size=[2, 2],
            padding='final'
        ),
        layers.ReshapeSpatialToDense(),
        layers.RootSum(
            return_weighted_child_logits=False,
            logspace_accumulators=False,
            backprop_mode=backprop_mode,
            dimension_permutation=spn.dimension_permutation.DimensionPermutation.SCOPES_DECOMPS_FIRST,
            accumulator_initializer=initializers.EpsilonInverseFanIn(
                axis=0, epsilon=1e-4)
        )
    ])
    return sum_product_network


sum_product_network = build_sum_product_network(
    backprop_mode=spn.BackpropMode.HARD_EM_UNWEIGHTED)

import tensorflow as tf
from libspn_keras.optimizers import OnlineExpectationMaximization


def _normalize_img(img):
    img = tf.cast(img, tf.float32)
    img_mean = tf.reduce_mean(img)
    img_stddev = tf.math.reduce_std(img)
    img = (img - img_mean) / (img_stddev + 1e-8)
    img = tf.expand_dims(img, axis=-1)
    return (img,)


batch_size = 64


def get_train_dataset():
    return (
        tf.data.Dataset.from_tensor_slices((train_x,))
            .shuffle(100000)
            .batch(batch_size)
            .map(_normalize_img)
    )


@tf.function
def train_one_step(model, optimizer, x):
    with tf.GradientTape() as tape:
        log_marginal_likelihood = model(x)
        loss = -tf.reduce_mean(log_marginal_likelihood)

    grads = tape.gradient(loss, model.trainable_variables)
    optimizer.apply_gradients(zip(grads, model.trainable_variables))

    return loss


def train(model, optimizer):
    step = 0
    for _ in range(10):
        for (x,) in get_train_dataset():
            loss = train_one_step(model, optimizer, x)
            if step % 10 == 0:
                tf.print('Step', step, ': loss', loss)
            step += 1


optimizer = OnlineExpectationMaximization()

train(sum_product_network, optimizer)

import matplotlib.pyplot as plt
sum_product_network_for_completion = build_sum_product_network(
    backprop_mode=spn.BackpropMode.GRADIENT)
sum_product_network_for_completion.set_weights(
    sum_product_network.get_weights())


class CompletionModel(keras.Model):

    def __init__(self, sequential_spn, **kwargs):
        super(CompletionModel, self).__init__(**kwargs)
        self.leaf = sequential_spn.layers[0]
        self.stack = sequential_spn.layers[1:]

    def _apply_stack(self, x):
        for layer in self.stack:
            x = layer(x)
        return x

    def call(self, input):
        img, evidence_mask = input

        orig_img = tf.identity(img)
        img = tf.cast(img, tf.float32)
        img_mean = tf.reduce_mean(img, axis=[1, 2, 3], keepdims=True)
        img_stddev = tf.math.reduce_std(img, axis=[1, 2, 3], keepdims=True)
        img = (img - img_mean) / (img_stddev + 1e-8)

        leaf_out = self.leaf(img)
        leaf_out = tf.where(evidence_mask, leaf_out, tf.zeros_like(leaf_out))
        with tf.GradientTape() as g:
            g.watch(leaf_out)
            sum_product_stack_out = self._apply_stack(leaf_out)
        dlog_root_dlog_leaf = g.gradient(sum_product_stack_out, leaf_out)
        leaf_modes = self.leaf.get_modes()
        dlog_root_dlog_leaf = tf.expand_dims(dlog_root_dlog_leaf, axis=-1)
        completion_nominator = tf.reduce_sum(
            leaf_modes * dlog_root_dlog_leaf, axis=-2)
        completion_denominator = tf.reduce_sum(
            dlog_root_dlog_leaf, axis=-2)
        completion_out = completion_nominator / completion_denominator
        completion_out = completion_out * (img_stddev + 1e-8) + img_mean
        completion_out = tf.where(evidence_mask, orig_img, completion_out)

        return completion_out


completion_model = CompletionModel(sum_product_network_for_completion)


def eval(model, x, omit_side):
    print("omitting ", omit_side)
    x = tf.expand_dims(x, axis=-1)
    evidence_mask = get_evidence_mask(omit_side).astype(np.bool)
    completion_out = model([x, evidence_mask])
    completion_out_completed_only = \
        tf.boolean_mask(completion_out, tf.logical_not(evidence_mask))
    input_completed_only = \
        tf.boolean_mask(x, tf.logical_not(evidence_mask))
    tf.print("MSE: ", tf.reduce_mean(tf.math.squared_difference(
        completion_out_completed_only, input_completed_only)))
    image_grid = make_image_grid(completion_out.numpy(), num_rows=5)

    plt.figure(figsize=(16, 16))
    plt.imshow(image_grid.squeeze(), cmap='gray')
    plt.show()


def make_image_grid(images, num_rows):
    images_per_row = np.split(images, axis=0, indices_or_sections=num_rows)
    rows = [np.concatenate(imgs, axis=1) for imgs in images_per_row]
    full_grid = np.concatenate(rows, axis=0)
    return full_grid


def get_evidence_mask(omit_side):
    if omit_side == "top":
        return np.concatenate(
            [np.zeros([50, 32, 64, 1]), np.ones([50, 32, 64, 1])], axis=1)
    elif omit_side == 'bottom':
        return np.concatenate(
            [np.ones([50, 32, 64, 1]), np.zeros([50, 32, 64, 1])], axis=1)
    elif omit_side == 'right':
        return np.concatenate(
            [np.ones([50, 64, 32, 1]), np.zeros([50, 64, 32, 1])], axis=2)
    elif omit_side == 'left':
        return np.concatenate(
            [np.zeros([50, 64, 32, 1]), np.ones([50, 64, 32, 1])], axis=2)
    else:
        raise ValueError("We have a problem")


eval(completion_model, test_x, 'top')
eval(completion_model, test_x, 'bottom')
eval(completion_model, test_x, 'left')
eval(completion_model, test_x, 'right')


